{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c4cd55-0c5d-4698-868e-77749036e361",
   "metadata": {},
   "source": [
    "Q1.**Q1. What is Bayes' theorem?**\n",
    "Bayes' theorem is a fundamental concept in probability theory and statistics. It describes how to update the probability of a hypothesis (or event) based on new evidence or information. The theorem is named after Thomas Bayes, an 18th-century statistician and theologian who contributed to the development of probability theory.\n",
    "\n",
    "**Q2. What is the formula for Bayes' theorem?**\n",
    "Bayes' theorem can be mathematically represented as follows:\n",
    "\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\]\n",
    "\n",
    "Where:\n",
    "- \\( P(A|B) \\) is the probability of event A occurring given that event B has occurred.\n",
    "\n",
    "- \\( P(B|A) \\) is the probability of event B occurring given that event A has occurred.\n",
    "\n",
    "- \\( P(A) \\) is the prior probability of event A occurring.\n",
    "\n",
    "- \\( P(B) \\) is the prior probability of event B occurring.\n",
    "\n",
    "**Q3. How is Bayes' theorem used in practice?**\n",
    "Bayes' theorem is widely used in various fields, including statistics, machine learning, and data science. It's used for tasks such as spam email detection, medical diagnosis, recommendation systems, and more. By updating probabilities based on new evidence, it helps make better decisions in situations with uncertainty.\n",
    "\n",
    "**Q4. What is the relationship between Bayes' theorem and conditional probability?**\n",
    "Bayes' theorem is essentially a formula that relates conditional probabilities. It provides a systematic way to update the probability of a hypothesis (a conditional event) when new evidence (another conditional event) is obtained. It's a powerful tool for reasoning about uncertain situations and updating beliefs based on observed data.\n",
    "\n",
    "**Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?**\n",
    "Naive Bayes classifiers are a family of algorithms based on Bayes' theorem and the assumption of independence among features. The choice of which Naive Bayes classifier to use depends on the nature of your data and the problem at hand:\n",
    "\n",
    "- **Gaussian Naive Bayes:** This is suitable for continuous numerical data. It assumes that the features follow a Gaussian distribution.\n",
    "\n",
    "- **Multinomial Naive Bayes:** This is often used for text classification tasks where the features are discrete (e.g., word counts in a document).\n",
    "\n",
    "- **Bernoulli Naive Bayes:** This is used for binary or categorical features. It's commonly used for text classification when working with binary features like presence or absence of words.\n",
    "\n",
    "The choice of classifier depends on the distribution of your data and the assumptions that align with your problem. It's a good practice to try different types and evaluate their performance using cross-validation or other relevant techniques to determine the best fit for your specific problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5e32f2-4a49-459e-ae0c-09424fa283b8",
   "metadata": {},
   "source": [
    "Q6.To predict the class using Naive Bayes, we need to calculate the conditional probabilities of the new instance's features given each class and then use Bayes' theorem to determine which class is more likely. Since the prior probabilities for each class are assumed to be equal, they will not affect the comparison of posterior probabilities. \n",
    "\n",
    "Let's calculate the conditional probabilities:\n",
    "\n",
    "Given:\n",
    "- X1 = 3\n",
    "- X2 = 4\n",
    "\n",
    "We need to calculate:\n",
    "\n",
    "\\[ P(Class=A | X1=3, X2=4) \\]\n",
    "\\[ P(Class=B | X1=3, X2=4) \\]\n",
    "\n",
    "We'll use the Naive Bayes assumption that the features are conditionally independent given the class.\n",
    "\n",
    "For Class A:\n",
    "\\[ P(X1=3 | Class=A) = \\frac{4}{13} \\]\n",
    "\\[ P(X2=4 | Class=A) = \\frac{3}{13} \\]\n",
    "\n",
    "For Class B:\n",
    "\\[ P(X1=3 | Class=B) = \\frac{1}{9} \\]\n",
    "\\[ P(X2=4 | Class=B) = \\frac{3}{9} \\]\n",
    "\n",
    "Now, we can use Bayes' theorem:\n",
    "\n",
    "\\[ P(Class=A | X1=3, X2=4) = \\frac{P(X1=3 | Class=A) \\cdot P(X2=4 | Class=A)}{P(X1=3, X2=4)} \\]\n",
    "\n",
    "\\[ P(Class=B | X1=3, X2=4) = \\frac{P(X1=3 | Class=B) \\cdot P(X2=4 | Class=B)}{P(X1=3, X2=4)} \\]\n",
    "\n",
    "Since we're only comparing the two classes, we don't need to calculate \\( P(X1=3, X2=4) \\) as it will be the same for both.\n",
    "\n",
    "So, we compare:\n",
    "\n",
    "\\[ P(Class=A | X1=3, X2=4) \\propto P(X1=3 | Class=A) \\cdot P(X2=4 | Class=A) \\]\n",
    "\\[ P(Class=B | X1=3, X2=4) \\propto P(X1=3 | Class=B) \\cdot P(X2=4 | Class=B) \\]\n",
    "\n",
    "Plugging in the values:\n",
    "\n",
    "For Class A:\n",
    "\\[ P(Class=A | X1=3, X2=4) \\propto \\frac{4}{13} \\cdot \\frac{3}{13} \\]\n",
    "\n",
    "For Class B:\n",
    "\\[ P(Class=B | X1=3, X2=4) \\propto \\frac{1}{9} \\cdot \\frac{3}{9} \\]\n",
    "\n",
    "Comparing the proportional values, we can see that \\( P(Class=A | X1=3, X2=4) \\) is larger. Therefore, Naive Bayes would predict that the new instance belongs to Class A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b685b7c9-f089-4333-b75f-43c9dfe6c004",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
